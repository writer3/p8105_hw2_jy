---
title: "p8105_HW2"
author: "John Yang"
date: "2024-10-02"
output: github_document
---

```{r, echo = FALSE, message = FALSE}
library(tidyverse)
library(readxl)
```

## Problem 1

### Reading and cleaning the data

```{r}
sub_df =
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", 
           na = c("NA", ".", "")) |> 
  janitor::clean_names() |> 
  select(line, station_name, station_latitude, station_longitude,
         route1, route2, route3, route4, route5, route6, route7,
         route8, route9, route10, route11,
         entry, entrance_type, vending, ada) |> 
  mutate(
    entry = case_match(
      entry,
      "YES" ~ 1,
      "NO" ~ 0,
    )
  )
```

### Description of Dataset

The dataset "sub_df" consists of NYC transit subway lines, stations, and the descriptions of station characteristics, such as location, entry, entrance type, vending, and ADA compliance. The following are the key variables:

  * `line` is a categorical variable describing the NYC transit subway lines.
  * `station_name`is a categorical variable describing the name of the station.
  * `station_latitude` is a continuous variable describing the latitude of the station in degrees.
  * `station_longitude` is a continuous variable describing the longitude of the station in degrees.
  * `route1`-`route11` are categorical variables describing the subway routes that stop at the station.
  * `entry`is a logical variable variable describing the whether there is an entry to the station. 
  * `entry_type`is categorical variables describing the entry types of the station. 
  * `vending` is a categorical variable whether there is vending or not in the station.
  * `ada`is a categorical describing whether there is ADA compliance in the station.

The dataset was cleaned, first, using the `janitor` function to convert the variable names to lowercase and replace spaces with "_". Then, variables of interests were selected. Then the entry variable was converted from character to a logical variable using the `mutate` function. The resulting dataset contains **`r nrow(sub_df)`** rows and **`r ncol(sub_df)`** columns. This data is tidy.

There are `r nrow(distinct(sub_df, line, station_name))` distinct stations in this dataset. 

There are `r nrow(distinct(filter(sub_df, ada == TRUE), line, station_name))` stations that are ADA compliant.

The proportion of station entrances / exits without vending allowing entrance is `r nrow(filter(sub_df, entry == 1 & vending == "NO")) / nrow(filter(sub_df, vending == "NO"))`.


Reformatting data so that that route number and route name are distinct variables. 

```{r}
sub_new_df = 
  sub_df |> 
  mutate(across(starts_with("route"), as.character)) |> 
  pivot_longer(
    cols = route1:route11,
    names_to = "routes_number",
    values_to = "route"
  )
```

There are `r nrow(distinct(filter(sub_new_df, route == "A", na.rm = TRUE), line, station_name))` distinct stations that serve the A train. 

Of the stations that serve the A train, `r nrow(distinct(filter(sub_new_df, route == "A" & ada == "TRUE", na.rm = TRUE), line, station_name))` are ADA compliant.





## Problem 2


### Reading and cleaning Mr. Trash Wheel dataset

```{r}
mr_df = 
  read_excel("data/202409 Trash Wheel Collection Data.xlsx", 
             sheet = "Mr. Trash Wheel",
             range = "A2:N653",
             na = c("NA", "", ".")) |> 
  janitor::clean_names() |> 
  rename(
    weight = "weight_tons",
    volume = "volume_cubic_yards") |> 
  mutate(
    sports_balls = as.integer(round(sports_balls)), 
    trash_wheel = "mr",
    year = as.numeric(year)
    ) |> 
  relocate(trash_wheel)
```


### Reading and cleaning Professor Trash Wheel dataset

```{r}
prof_df = 
  read_excel("data/202409 Trash Wheel Collection Data.xlsx", 
             sheet = "Professor Trash Wheel",
             range = "A2:M118",
             na = c("NA", "", ".")) |> 
  janitor::clean_names() |> 
  rename(
    weight = "weight_tons",
    volume = "volume_cubic_yards") |> 
  mutate(
    trash_wheel = "professor", 
    year = as.numeric(year)
    ) |> 
  relocate(trash_wheel)
```

### Reading and cleaning Gwynnda Trash Wheel dataset

```{r}
gwynnda_df = 
  read_excel("data/202409 Trash Wheel Collection Data.xlsx", 
             sheet = "Gwynnda Trash Wheel",
             range = "A2:L265",
             na = c("NA", "", ".")) |> 
  janitor::clean_names() |> 
  rename(
    weight = "weight_tons",
    volume = "volume_cubic_yards")|> 
  mutate(
    trash_wheel = "gwynnda",
    year = as.numeric(year)
    )|> 
  relocate(trash_wheel)
```


### Combining Trash Wheel datasets

```{r}
trash_wheel_df = 
  full_join (mr_df, prof_df) |> 
  full_join (x = _, y = gwynnda_df)
```

### Description of Dataset

The dataset "trash_wheel_df" consists of information on the trash_wheel type, dumpster number, date of collection, amount of total litter and litter type. The following are the key variables:

  * `trash_wheel` is a character variable that was added in describing the type of the trash_wheel.
  * `dumpster`is a numerical variable describing the dumpster number.
  * `month` is a character variable describing the month of collection.
  * `year` is numerical variable describing the year of collection.
  * `date` is a POSIXct data describing the year, month, and date of collection.
  * `weight`is a numerical variable variable describing weight of litters in tons. 
  * `volume`is a numerical variable describing the volume of litters in cubic yards.
  * `plastic_bottles` is a numerical variable describing the amount of plastic bottles.
  * `polystyrene` is a numerical variable describing the amount of polystyrene.
  * `cigarette_butts` is a numerical variable describing the amount of cigarette butts.
  * `glass_bottles` is a numerical variable describing the amount of glass bottles.
  * `plastic_bags` is a numerical variable describing the amount of plastic bags.
  * `wrappers` is a numerical variable describing the amount of wrappers.
  * `sports_balls` is a numerical variable in integers describing the amount of sports_balls.
  * `homes_powered` is a numerical variable describing the number of homes powered based on the amount of trash.

This dataset contains **`r nrow(trash_wheel_df)`** rows and **`r ncol(trash_wheel_df)`** columns. The total weight of trash collected by Professor Trash Wheel was `r sum(filter(trash_wheel_df, trash_wheel == "professor")$weight, na.rm = TRUE)` tons. The total number of cigarette butts collected by Gwynnda in June of 2022 was `r sum(filter(trash_wheel_df, trash_wheel == "gwynnda" & month == "June" & year == 2022)$cigarette_butts, na.rm = TRUE)`.




## Problem 3


### Import, clean, tidy, and wrangle bakers dataset

```{r}
bakers_df = 
  read_csv(
    file = "data/bakers.csv", 
    na = c("NA", "", "."))|>
  janitor::clean_names() |> 
  separate(baker_name, into = c("baker", "last_name"), sep = " ") |> 
  mutate(
    name_series = paste(baker, series, sep = "_")
    )
  
```

### Import, clean, tidy, and wrangle bakes dataset

```{r}
bakes_df = 
  read_csv(
    file = "data/bakes.csv", 
    na = c("NA", "", "."))|>
  janitor::clean_names()|> 
  mutate(name_series = paste(baker, series, sep = "_"))
  
```

### Import, clean, tidy, and wrangle results dataset

```{r}
results_df = 
  read_csv(
    file = 
      "data/results.csv", 
      skip = 2,
      na = c("NA", "", "."))|>
  janitor::clean_names()|> 
  mutate(name_series = paste(baker, series, sep = "_"))
  
```

### Merge datasets

```{r}
bakeoff_combined_df = 
  bakers_df |> 
  merge(bakes_df) |> 
  merge(results_df) |> 
  mutate(
    series = as.character(series),
    first_name = as.character(baker)) |> 
  select(-baker) |> 
  relocate(series, episode, first_name, last_name) |> 
  arrange(series, episode)
```

### using anti_join to check

```{r}
anti_join(bakers_df, bakeoff_combined_df, by = "name_series") 
anti_join(bakeoff_combined_df, bakes_df, by = "name_series") 
anti_join(bakeoff_combined_df, results_df, by = "name_series")
```


### Export as a csv 

```{r}
bakeoff_combined_df =
  bakeoff_combined_df |> 
    select(-name_series)

write.csv(bakeoff_combined_df,file='data/bakeoff_combined_df.csv', row.names = FALSE)
```


#### Bakers dataset cleaning process
The `Bakers` dataset was imported by labeling all missing data as "na". The dataset was cleaned using the janitor function. As a first step in making a key common variable, I separated the `baker_name` into `baker` and `last_name`. Then I made a `name_series` variable that I planned to create in other datasets based on available data to make a key common variable.

#### Bakes dataset cleaning process
The `Bakes` dataset was imported by labeling all missing data as "na". The dataset was cleaned using the janitor function. I made a `name_series`, which is a combination of first name of the baker and the series that they participated in to make a key common variable that was used in the merge process.

#### Results dataset cleaning process
The `Results` dataset was imported by skipping the first two rows that did not contain data and labeling all missing data as "na". The dataset was cleaned using the janitor function. 


#### Description of the dataset
The bakeoff_combined_df dataset combines `bakers`, `bakes`, and `results` datasets by the common variables of name_series that was created and series. This dataset contains key variables, including the information about bakers, such as their `first_name`, `last_name`, age, occupation and hometown. This dataset also includes information about the series and episodes the bakers participated in, their signature bake, show stopper, technical results, and their outcome (winner, star baker, etc.). Lastly, the dataset includes the viewership of each series and episode. This dataset contains **`r nrow(bakeoff_combined_df)`** rows and **`r ncol(bakeoff_combined_df)`** columns. 


### Create a reader-friendly table showing the star baker or winner of each episode in Seasons 5 through 10. Comment on this table – were there any predictable overall winners? Any surprises?

```{r}
winners_tb =
  bakeoff_combined_df |> 
  filter(result == "WINNER" | result == "STARBAKER") |> 
  filter(series >= 5) |> 
  select(series, episode, result) |> 
  arrange(series,episode)

print(winners_tb)
```

Import, clean, tidy, and organize the viewership data in viewers.csv. Show the first 10 rows of this dataset. What was the average viewership in Season 1? In Season 5?

### Import, clean, tidy, and wrangle viewers dataset

```{r}
viewers_df = 
  read_csv(
    file = "data/viewers.csv", 
    na = c("NA", "", "."))|>
  janitor::clean_names() |> 
  pivot_longer(
    cols = series_1:series_10,
    names_to = "series",
    values_to = "viewers",
    names_prefix = "series_"
  )

print(head(viewers_df, 10))
```

average viewership in season 1 
```{r}
average_season_1 = 
  viewers_df |> 
  filter(series == "1") |> 
  summarise(average_viewers = mean(viewers, na.rm = TRUE))
```
average viewership in season 1 was `r average_season_1`

average viewership in season 5
```{r}
average_season_5 = 
  viewers_df |> 
  filter(series == "5") |> 
  summarise(average_viewers = mean(viewers, na.rm = TRUE))
```

average viewership in season 5 was `r average_season_5`