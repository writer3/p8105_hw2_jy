p8105_HW2
================
John Yang
2024-10-02

## Problem 1

### Reading and cleaning the data

``` r
sub_df =
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", 
           na = c("NA", ".", "")) |> 
  janitor::clean_names() |> 
  select(line, station_name, station_latitude, station_longitude,
         route1, route2, route3, route4, route5, route6, route7,
         route8, route9, route10, route11,
         entry, entrance_type, vending, ada) |> 
  mutate(
    entry = case_match(
      entry,
      "YES" ~ 1,
      "NO" ~ 0,
    )
  )
```

    ## Rows: 1868 Columns: 32
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (22): Division, Line, Station Name, Route1, Route2, Route3, Route4, Rout...
    ## dbl  (8): Station Latitude, Station Longitude, Route8, Route9, Route10, Rout...
    ## lgl  (2): ADA, Free Crossover
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

### Description of Dataset

The dataset “sub_df” consists of NYC transit subway lines, stations, and
the descriptions of station characteristics, such as location, entry,
entrance type, vending, and ADA compliance. The following are the key
variables:

- `line` is a categorical variable describing the NYC transit subway
  lines.
- `station_name`is a categorical variable describing the name of the
  station.
- `station_latitude` is a continuous variable describing the latitude of
  the station in degrees.
- `station_longitude` is a continuous variable describing the longitude
  of the station in degrees.
- `route1`-`route11` are categorical variables describing the subway
  routes that stop at the station.
- `entry`is a logical variable variable describing the whether there is
  an entry to the station.
- `entry_type`is categorical variables describing the entry types of the
  station.
- `vending` is a categorical variable whether there is vending or not in
  the station.
- `ada`is a categorical describing whether there is ADA compliance in
  the station.

The dataset was cleaned, first, using the `janitor` function to convert
the variable names to lowercase and replace spaces with “\_“. Then,
variables of interests were selected. Then the entry variable was
converted from character to a logical variable using the `mutate`
function. The resulting dataset contains **1868** rows and **19**
columns. This data is tidy.

There are 465 distinct stations in this dataset.

There are 84 stations that are ADA compliant.

The proportion of station entrances / exits without vending allowing
entrance is 0.3770492.

Reformatting data so that that route number and route name are distinct
variables.

``` r
sub_new_df = 
  sub_df |> 
  mutate(across(starts_with("route"), as.character)) |> 
  pivot_longer(
    cols = route1:route11,
    names_to = "routes_number",
    values_to = "route"
  )
```

There are 60 distinct stations that serve the A train.

Of the stations that serve the A train, 17 are ADA compliant.

## Problem 2

### Reading and cleaning Mr. Trash Wheel dataset

``` r
mr_df = 
  read_excel("data/202409 Trash Wheel Collection Data.xlsx", 
             sheet = "Mr. Trash Wheel",
             range = "A2:N653",
             na = c("NA", "", ".")) |> 
  janitor::clean_names() |> 
  rename(
    weight = "weight_tons",
    volume = "volume_cubic_yards") |> 
  mutate(
    sports_balls = as.integer(round(sports_balls)), 
    trash_wheel = "mr",
    year = as.numeric(year)
    ) |> 
  relocate(trash_wheel)
```

### Reading and cleaning Professor Trash Wheel dataset

``` r
prof_df = 
  read_excel("data/202409 Trash Wheel Collection Data.xlsx", 
             sheet = "Professor Trash Wheel",
             range = "A2:M118",
             na = c("NA", "", ".")) |> 
  janitor::clean_names() |> 
  rename(
    weight = "weight_tons",
    volume = "volume_cubic_yards") |> 
  mutate(
    trash_wheel = "professor", 
    year = as.numeric(year)
    ) |> 
  relocate(trash_wheel)
```

### Reading and cleaning Gwynnda Trash Wheel dataset

``` r
gwynnda_df = 
  read_excel("data/202409 Trash Wheel Collection Data.xlsx", 
             sheet = "Gwynnda Trash Wheel",
             range = "A2:L265",
             na = c("NA", "", ".")) |> 
  janitor::clean_names() |> 
  rename(
    weight = "weight_tons",
    volume = "volume_cubic_yards")|> 
  mutate(
    trash_wheel = "gwynnda",
    year = as.numeric(year)
    )|> 
  relocate(trash_wheel)
```

### Combining Trash Wheel datasets

``` r
trash_wheel_df = 
  full_join (mr_df, prof_df) |> 
  full_join (x = _, y = gwynnda_df)
```

    ## Joining with `by = join_by(trash_wheel, dumpster, month, year, date, weight,
    ## volume, plastic_bottles, polystyrene, cigarette_butts, glass_bottles,
    ## plastic_bags, wrappers, homes_powered)`
    ## Joining with `by = join_by(trash_wheel, dumpster, month, year, date, weight,
    ## volume, plastic_bottles, polystyrene, cigarette_butts, plastic_bags, wrappers,
    ## homes_powered)`

### Description of Dataset

The dataset “trash_wheel_df” consists of information on the trash_wheel
type, dumpster number, date of collection, amount of total litter and
litter type. The following are the key variables:

- `trash_wheel` is a character variable that was added in describing the
  type of the trash_wheel.
- `dumpster`is a numerical variable describing the dumpster number.
- `month` is a character variable describing the month of collection.
- `year` is numerical variable describing the year of collection.
- `date` is a POSIXct data describing the year, month, and date of
  collection.
- `weight`is a numerical variable variable describing weight of litters
  in tons.
- `volume`is a numerical variable describing the volume of litters in
  cubic yards.
- `plastic_bottles` is a numerical variable describing the amount of
  plastic bottles.
- `polystyrene` is a numerical variable describing the amount of
  polystyrene.
- `cigarette_butts` is a numerical variable describing the amount of
  cigarette butts.
- `glass_bottles` is a numerical variable describing the amount of glass
  bottles.
- `plastic_bags` is a numerical variable describing the amount of
  plastic bags.
- `wrappers` is a numerical variable describing the amount of wrappers.
- `sports_balls` is a numerical variable in integers describing the
  amount of sports_balls.
- `homes_powered` is a numerical variable describing the number of homes
  powered based on the amount of trash.

This dataset contains **1030** rows and **15** columns. The total weight
of trash collected by Professor Trash Wheel was 241.26 tons. The total
number of cigarette butts collected by Gwynnda in June of 2022 was
1.812^{4}.

## Problem 3

### Import, clean, tidy, and wrangle bakers dataset

``` r
bakers_df = 
  read_csv(
    file = "data/bakers.csv", 
    na = c("NA", "", "."))|>
  janitor::clean_names() |> 
  separate(baker_name, into = c("baker", "last_name"), sep = " ") |> 
  mutate(
    name_series = paste(baker, series, sep = "_")
    )
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

### Import, clean, tidy, and wrangle bakes dataset

``` r
bakes_df = 
  read_csv(
    file = "data/bakes.csv", 
    na = c("NA", "", "."))|>
  janitor::clean_names()|> 
  mutate(name_series = paste(baker, series, sep = "_"))
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

### Import, clean, tidy, and wrangle results dataset

``` r
results_df = 
  read_csv(
    file = 
      "data/results.csv", 
      skip = 2,
      na = c("NA", "", "."))|>
  janitor::clean_names()|> 
  mutate(name_series = paste(baker, series, sep = "_"))
```

    ## Rows: 1136 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (2): baker, result
    ## dbl (3): series, episode, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

### Merge datasets

``` r
bakeoff_combined_df = 
  bakers_df |> 
  merge(bakes_df) |> 
  merge(results_df) |> 
  mutate(
    series = as.character(series),
    first_name = as.character(baker)
  ) |> 
  select(-baker) |> 
  relocate(series, episode, first_name, last_name) |> 
  arrange(series, episode)
```

### using anti_join to check

``` r
anti_join(bakers_df, bakeoff_combined_df, by = "name_series") 
```

    ## # A tibble: 26 × 7
    ##    baker  last_name       series baker_age baker_occupation hometown name_series
    ##    <chr>  <chr>            <dbl>     <dbl> <chr>            <chr>    <chr>      
    ##  1 Alice  Fevronia            10        28 Geography teach… Essex    Alice_10   
    ##  2 Amelia LeBruin             10        24 Fashion designer Halifax  Amelia_10  
    ##  3 Antony Amourdoux            9        30 Banker           London   Antony_9   
    ##  4 Briony Williams             9        33 Full-time parent Bristol  Briony_9   
    ##  5 Dan    Beasley-Harling      9        36 Full-time parent London   Dan_9      
    ##  6 Dan    Chambers            10        32 Support worker   Rotherh… Dan_10     
    ##  7 David  Atherton            10        36 International h… Whitby   David_10   
    ##  8 Helena Garcia              10        40 Online project … Leeds    Helena_10  
    ##  9 Henry  Bird                10        20 Student          Durham   Henry_10   
    ## 10 Imelda McCarron             9        33 Countryside rec… County … Imelda_9   
    ## # ℹ 16 more rows

``` r
anti_join(bakeoff_combined_df, bakes_df, by = "name_series") 
```

    ##  [1] series           episode          first_name       last_name       
    ##  [5] name_series      baker_age        baker_occupation hometown        
    ##  [9] signature_bake   show_stopper     technical        result          
    ## <0 rows> (or 0-length row.names)

``` r
anti_join(bakeoff_combined_df, results_df, by = "name_series")
```

    ##  [1] series           episode          first_name       last_name       
    ##  [5] name_series      baker_age        baker_occupation hometown        
    ##  [9] signature_bake   show_stopper     technical        result          
    ## <0 rows> (or 0-length row.names)

### Export as a csv

``` r
bakeoff_combined_df =
  bakeoff_combined_df |> 
    select(-name_series)

write.csv(bakeoff_combined_df,file='data/bakeoff_combined_df.csv', row.names = FALSE)
```

#### Bakers dataset cleaning process

The `Bakers` dataset was imported by labeling all missing data as “na”.
The dataset was cleaned using the janitor function. As a first step in
making a key common variable, I separated the `baker_name` into `baker`
and `last_name`. Then I made a `name_series` variable that I planned to
create in other datasets based on available data to make a key common
variable.

#### Bakes dataset cleaning process

The `Bakes` dataset was imported by labeling all missing data as “na”.
The dataset was cleaned using the janitor function. I made a
`name_series`, which is a combination of first name of the baker and the
series that they participated in to make a key common variable that was
used in the merge process.

#### Results dataset cleaning process

The `Results` dataset was imported by skipping the first two rows that
did not contain data and labeling all missing data as “na”. The dataset
was cleaned using the janitor function.

#### Description of the dataset

The bakeoff_combined_df dataset combines `bakers`, `bakes`, and
`results` datasets by the common variables of name_series that was
created and series. This dataset contains key variables, including the
information about bakers, such as their `first_name`, `last_name`, age,
occupation and hometown. This dataset also includes information about
the series and episodes the bakers participated in, their signature
bake, show stopper, technical results, and their outcome (winner, star
baker, etc.). Lastly, the dataset includes the viewership of each series
and episode. This dataset contains **540** rows and **11** columns.

### Create a reader-friendly table showing the star baker or winner of each episode in Seasons 5 through 10. Comment on this table – were there any predictable overall winners? Any surprises?

``` r
winners_tb =
  bakeoff_combined_df |> 
  filter(result == "WINNER" | result == "STARBAKER", series >= 5) |> 
  select(series, episode, result) |> 
  arrange(series, episode)


print(winners_tb)
```

    ##   series episode result
    ## 1      5      10 WINNER
    ## 2      6      10 WINNER
    ## 3      7      10 WINNER
    ## 4      8      10 WINNER

Table consist of 1 winner from each season. All episodes are 10 as
expected since the winners are announced in episode 10.

Import, clean, tidy, and organize the viewership data in viewers.csv.
Show the first 10 rows of this dataset. What was the average viewership
in Season 1? In Season 5?

### Import, clean, tidy, and wrangle viewers dataset

``` r
viewers_df = 
  read_csv(
    file = "data/viewers.csv", 
    na = c("NA", "", "."))|>
  janitor::clean_names() |> 
  pivot_longer(
    cols = series_1:series_10,
    names_to = "series",
    values_to = "viewers",
    names_prefix = "series_"
  )
```

    ## Rows: 10 Columns: 11
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (11): Episode, Series 1, Series 2, Series 3, Series 4, Series 5, Series ...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
print(head(viewers_df, 10))
```

    ## # A tibble: 10 × 3
    ##    episode series viewers
    ##      <dbl> <chr>    <dbl>
    ##  1       1 1         2.24
    ##  2       1 2         3.1 
    ##  3       1 3         3.85
    ##  4       1 4         6.6 
    ##  5       1 5         8.51
    ##  6       1 6        11.6 
    ##  7       1 7        13.6 
    ##  8       1 8         9.46
    ##  9       1 9         9.55
    ## 10       1 10        9.62

average viewership in season 1

``` r
average_season_1 = 
  viewers_df |> 
  filter(series == "1") |> 
  summarise(average_viewers = mean(viewers, na.rm = TRUE))
```

average viewership in season 1 was 2.77

average viewership in season 5

``` r
average_season_5 = 
  viewers_df |> 
  filter(series == "5") |> 
  summarise(average_viewers = mean(viewers, na.rm = TRUE))
```

average viewership in season 5 was 10.0393
